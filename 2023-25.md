# 云原生技术动态 2023 年第二十五期

## 分布式系统

**1.** **向量数据库？那咱们就浅谈一下吧**

https://mp.weixin.qq.com/s/VqEjstw_HP-ea6Sn9X9Utg

**摘要:** 向量数据库在AI 原生应用中起着非常关键的作用, 特别适合用来补充私域知识, 这篇文章介绍了向量数据库的基本原理和选择合适的向量数据库需要考虑的维度.

**2.** **PyTorch 源码解读之流水线并行**

https://mp.weixin.qq.com/s/x4tbc2HAhkDqCD87TcESdw

**摘要:** 随着 Transformer 架构模型的广泛应用，大语言模型的参数量也是水涨船高，像是 GPT-3 就已经达到了惊人的 175B 参数量，GPT-4 更是被曝有 1800B 的参数量。为了训练这样的大模型，并且尽可能提高 GPU 的利用率，流水线并行（Pipeline Parallelism, PP）的训练策略应运而生。PyTorch 也实现了一套流水线并行的解决方法。本文将介绍 torch.distributed.pipeline.sync 的实现细节。

## 云计算技术

**1.** **阿里云云网络演进**

https://mp.weixin.qq.com/s/UVX-n1iF-X7KhgwJ6XxFGg

**摘要:** 这篇文章介绍了阿里云网络技术的三个演化阶段, 从经典网络, 到大规模网络控制器的架构演化, 再到软硬结合的高性能网关和业务网元的 NFV 化, 高度概括了 VPC 网络技术的核心演化思路.

**2.** **如何构建基于大模型的App**

https://mp.weixin.qq.com/s/xE1AFN4xuVECPgwxDokWvw

**摘要:** 智能原生（AI Native），往往是指那些没有大模型就无法成立的应用，那是一些新的业务机会和挑战, 这篇文章总结了构建 AI 原生应用的基本模式, 构建一个基于大模型的应用并没有想象中的那么困难， 但充分利用大模型的能力来为业务赋能却不是那么容易.

## 云开发技术

**1.** **逐步理解Transformers的数学原理**

https://mp.weixin.qq.com/s/aVnUP3YZ6Tdqgh_A2pmFiA

**摘要:** transformer架构可能看起来很恐怖，这篇文章通过提供一个全面的数学示例阐明它的原理, 希望帮助大家简化对transformer架构的理解。

**2.** **大模型LangChain框架基础与使用示例**

https://mp.weixin.qq.com/s/KrWM3cMywMvYUiawRZ94Gg

**摘要:** LangChain 中的 Data Connection 将 LLM 与万物互联，给 LangChain 构建的应用带来了无限可能，而 Agent 又为应用开发中非常常见的”事件驱动“这一开发框架提供了偷懒的途径，将分支决策的工作交给 LLM，这又进一步简化了应用开发的工作；结合基于高度抽象的 Model I/O 及 Memory 等组件，LangChain 让开发者能够更快，更好更灵活地实现 LLM 助手、对话机器人等应用，极大地降低了 LLM 的使用门槛。

## 技术之外

**1.** **红杉资本：生成式AI的第二幕**

https://mp.weixin.qq.com/s/jnEuT5b10b4S6XprM57gBg

**摘要:** 一年前，红杉资本发表了广为传播的文章《Generative AI: A Creative New World》，吹响了向生成式AI创业进军的浪潮。今天，红杉再次发文《Generative AI‘s Act Two》，对过去一年里生成式AI相关创业的发展进行了反思和总结。

**2.** **微软开源AI语义内核：从句法向语义的转变**

https://mp.weixin.qq.com/s/5V_u0fRP8GHDfvpXyzUzcA

**摘要:** 微软最近开源了一款 Semantic Kernel（语义内核）产品，这是一种轻量级软件开发工具包 (SDK)，允许开发人员将 AI 技术集成到他们的应用程序中。SK（Semantic Kernel）让传统的编程语言，如c#和Python，与最新的大型语言模型(LLM)  AI 提示相结合，具有提示模板、链接和规划功能。 
