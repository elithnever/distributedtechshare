# 云原生技术动态 2023 年第二十七期

## 分布式系统

**1.** **Azure下一代块存储架构：深度技术解析**

https://mp.weixin.qq.com/s/EyaDM8Oz-TqvhEkmnchdng

**摘要:** Azure Disk为Azure虚拟机提供块存储，并是Azure IaaS平台的核心支柱之一。这篇文章概述Direct Drive - Azure的下一代块存储架构, 描述了在云规模下提供持久、高可用、高性能Disk所面临的挑战，以及克服这些挑战的软件和硬件创新。

**2.** **充分发挥NVMe存储的潜力：高性能存储引擎的设计与实现**

https://mp.weixin.qq.com/s/pdIyXl3Z2NZ936VfVHSgjw

**摘要:** 基于闪存的NVMe SSD具有低廉的价格并提供高吞吐量。将多个这些设备整合到单个服务器中，可以实现高达1000万IOPS。然而现有的数据库系统和存储引擎仅能发挥这一性能潜力的一小部分。这篇文章展示了通过I/O优化的存储引擎设计可以减小硬件和软件之间性能差距的可能性。在内存资源严重有限的情况下，数据集大小达到主内存的10倍时，我们的系统能够每秒处理超过100万个TPC-C事务。

## 云计算技术

**1.** **Pingmesh：一个用于数据中心网络延迟测量与分析的大规模系统**

https://mp.weixin.qq.com/s/cFRFQaakOk3lK7URXmWHFg

**摘要:** 这篇文章通过设计和实现Pingmesh展示了建立一个大规模网络延迟测量和分析系统的可行性。通过让每个服务器参与，利用 pingmesh提供了所有服务器的延迟数据。

**2.** **网络的智能应该放在哪里：网卡、交换机还是xPU**

https://mp.weixin.qq.com/s/veE-PHuWEMkx14zPug-1_g

**摘要:** 随着大模型和 AI 基础设施的发展, 各种形式的智能网卡和智能网络设备也表现了多种不同形态, 这篇文章系统性分析了不同形式网络智能的发展过程, 未来 AI 和云计算的融合也必将是充满期待.

## 云开发技术

**1.** **RAG（检索增强生成）技术详解：基于垂直领域专有数据的Chatbots是如何实现的**

https://mp.weixin.qq.com/s/IEGD8AIZw3cJwSnL2J6FUg

**摘要:** 文章详细梳理了 RAG 技术的具体实现原理。首先，RAG 将用户输入的问题与知识库中的私有数据进行匹配，获取相关知识片段。然后，通过预训练的大语言模型，用提取到的知识片段来增强对问题的回答生成过程。在知识提取步骤，借助词向量的相似度找到与用户提出的问题最匹配的内容。生成回答时，直接向语言模型提供增强知识来指导其产出更符合语境的回答。

**2.** **LLM内核计算核心-CUDA MatMul编程介绍**

https://mp.weixin.qq.com/s/nN9KslRaqjCIRrAGCJskDg

**摘要:** LLM核心算子是注意力机制，可以转化为矩阵乘，这篇文章以矩阵乘为例介绍cuda编程机制.

## 技术之外

**1.** **试过GPT-4V后，微软写了个166页的测评报告，业内人士：高级用户必读**

https://mp.weixin.qq.com/s/VVzd2TP3rHAs2cOc03Vaqw

**摘要:** 该报告共分为11个章节，重点是对最新模型 GPT-4V(ision)进行分析，以加深大众对 LMM（大型多模态模型） 的理解。文章用很大篇幅介绍了GPT-4V可以执行的任务，包括用测试样本来探索GPT-4V的质量和通用性，现阶段GPT-4V能够支持的输入和工作模式，以及提示模型的有效方法。

**2.** **如何选择最适合你的LLM优化方法：全面微调、PEFT、提示工程和RAG对比分析**

https://mp.weixin.qq.com/s/w0BaUbXIg1g8DvEQ6nIoDw

**摘要:** 这篇文章介绍了 LLM 四种使用方法, 这些方法在所需专业知识、成本和适用性方面各有不同。本文介绍了每种方法，揭示它们的细微差异、成本和最佳使用案例。通过深入了解哪种方法最适合你的项目，你将能够更好地使用LLM。



