# 云原生技术动态 2023 年第三十三期

## 分布式系统

**1.** **Paxos的魔法学研究报告**

https://mp.weixin.qq.com/s/CVa_gUdCtdMEURs40CiXsA

**摘要:** 本文试图从异次元魔法学的角度对Paxos算法做一个解读，建立Paxos算法背后简明的魔法学图像，从而实现我们对这个算法的直观理解。

**2.** **亚马逊 CTO 12年 re:Invent 架构课**

https://mp.weixin.qq.com/s/ngxQSXgdLCwu6xz2SUQrHw

**摘要:** 2023年亚马逊 CTO Werner Vogels的主题演讲中，***“俭约架构”*** 的七条黄金法则，引发广泛学习和讨论，架构的约束一直都在，但随着大环境和业务的发展变化，Werner 提出我们要不断审视我们的架构.

## 云计算技术

**1.** **Kubernetes v1.29 新特性一览**

https://mp.weixin.qq.com/s/tKft1Ayn8cAafUf0DkTrBg

**摘要:** Kubernetes v1.29 是 2023 年的第三个大版本更新，也是今年的最后一个大版本，包含了 49 项主要的更新。而今年发布的第一个版本 v1.27 有近 60 项，第二个版本 v1.28 有 46 项。尽管 Kubernetes 已经发布快 10 年了，Kubernetes 的生命力仍然很旺盛！

**2.** **优化容器工作负载：Kubernetes装箱的效益和挑战**

https://mp.weixin.qq.com/s/zUPxex583btvBCFkHcFCgA

**摘要:** 在 Kubernetes 中，装箱的概念涉及在节点内部战略性地放置容器或“箱子（bin）”，以最大化资源利用率和减少资源浪费。如果实施得当，可以实现对硬件资源更有效的利用，并降低基础设施成本。本文探讨了在 Kubernetes 中进行装箱的复杂性，讨论与这种方法相关的挑战和权衡，并提供在企业中实现装箱的示例和最佳实践。

## 大模型技术

**1.** **分析transformer模型的参数量、计算量、中间激活、KV cache**

https://mp.weixin.qq.com/s/bwTSJgmTbepLsHjhPeyvog

**摘要:** 这篇文章详细分析了transformer模型的参数量、计算量、中间激活和KV cache，有助于理解大模型训练和推断过程中的显存效率和计算效率.

**2.** **当计算撞上内存墙：Attention！注意力机制及其优化算法浅析**

https://mp.weixin.qq.com/s/N2avU-j9sxfh3QEkg8VBjQ

**摘要:** 本文通过对 Attention 机制的理解，从算法的角度去分析当前深度学习系统中 Attention 对于内存容量和带宽的需求。通过介绍以 FlashAttention 和 PagedAttention 为代表的对标准 Attention 的各种优化算法，理解内存对于大语言模型的上下文长度的增长的限制。

## 技术之外

**1.** **上云下云是小白的争论，重点在于现代架构！**

https://mp.weixin.qq.com/s/akv7NolhymU4gfh9s6n6yw

**摘要:** 云计算，开辟了一个新的时代，以云原生的姿势上云，是不会有下云的忧虑，我们坚信，所有的基础软件，都值得基于云重新设计，以发挥出云全部的优势。

**2.** **英伟达的另一张王牌**

https://mp.weixin.qq.com/s/CmTa1sM5OloN56cOx_B4iw

**摘要:** 带宽的大小决定了单位时间向GPU传输的数据总量, 如今衡量GPU的质量，带宽已经成为算力之外最重要的指标。英伟达的伟大在于，它以高度的前瞻性，几乎以一己之力开辟了一条人工智能的高速公路。而它的成功在于，黄仁勋在每一个你可能经过的车道，都提前修好了收费站。

