# 云原生技术追踪 2023 年第二十九期

## 分布式系统

**1.** **NVMeDirect：面向基于NVMe固态硬盘存储应用优化的一种用户空间I/O框架[翻译]**

https://mp.weixin.qq.com/s/2ul0X7d8v_VR6nIp3_XLEQ

**摘要:** 在本论文中，我们提出了一个用户级的I/O架构，允许用户应用程序直接访问商用的NVMe固态硬盘，而无需做任何硬件修改。而且，该框架给用户提供了灵活性，用户应用程序可以选择自己的I/O策略，包括I/O完成方法、缓存和I/O调度。评估结果表明，我们的提出的框架优于基于内核的I/O，在微基准测试中性能提升高达30%，应用到Redis上性能提升高达15%。

**2.** **NVIDIA Spectrum X的技术分析和启示**

https://mp.weixin.qq.com/s/Ab3mhK0mMVpQ-zRpZiOpnw

**摘要:** 通过本次发布，NVIDIA正式承认在云数据中心环境中，以太网仍然是呼声最高的互联解决方案。Spectrum X采用端到端优化的解决方案思路，其核心由BF3 DPU、Spectrum交换机、NetQ等软件栈构成，在交换机层面，AR和端网协同是其核心技术，背后离不开其网络可观测能力（WJH引擎）和可视化平台NetQ。

## 云计算技术

**1.** **Open vSwitch全解析-理解流表**

https://mp.weixin.qq.com/s/ARP26ZPbwRy30qAP-eM3kQ

**摘要:** 流表是SDN 领域最核心的概念和模型, 这篇文章对 OVS 的流表进行了基本的介绍, 方便加深对流表的认识.

**2.** **阿里可预期网络-HPN7.0解读**

https://mp.weixin.qq.com/s/kDzJ1MEaizd0fnmhuCm9PQ

**摘要:** 本次可预期网络的关键词是端网融合, 分析了阿里云 HPN7.0 的网络技术, 实现了 400G 单端口网络和 51.2T 自研交换机, HPN7.0从架构上终于还是走向了多轨道优化的网络拓扑，只不过叠加了双上联和双平面，这时候ACCL就显得非常重要了。拥塞控制方面，明确采用自适应路由，通过网卡Reorder解决乱序问题，通过Last Hop PFC解决拥塞扩散问题，引入了vSolar解决虚拟化开销问题。

## 大模型技术

**1.** **Llama2 官方入门指南 (中文版)**

https://mp.weixin.qq.com/s/QOyYgn8q1XhqloW6Wfp-HA

**摘要:** 本指南提供了帮助您设置Llama所需的信息和资源，包括如何访问模型、托管、操作指南和集成指南。另外，您还会找到一些补充材料，以便在使用Llama构建时为您提供更多帮助。

**2.** **解锁 vLLM：大语言模型推理的速度与效率双提升**

https://mp.weixin.qq.com/s/IrmvFiBMvItzIvoKBQVfpw

**摘要:** vLLM是一个端到端的服务系统，它的构建包括一个基于FastAPI的前端和一个基于GPU的推理引擎。通过扩展OpenAI API接口，前端允许用户为每个请求定制采样参数，从而提供了一种灵活且用户友好的方式来控制模型的生成过程。

## 技术之外

**1.** **ChatGPT：GPT-4 架构揭秘**

https://mp.weixin.qq.com/s/B-XQRuns_U9Li5jXW-sOuw

**摘要:** OpenAI 自 GPT-3.5 之后的版本就未开源，关于 GPT-3.5、GPT-4 的所有信息就像是一个黑盒，被 OpenAI 紧紧的包裹起来。这篇文章来自网上的各种爆料，相比于之前，这次爆出的信息更多更大。

**2.** **开源语言大模型演进史：高质量基础模型竞赛**

https://mp.weixin.qq.com/s/MrgJt0a1Z8Su1xNT62QMeg

**摘要:** 本文是开源 LLM 发展史系列文章的第二部分, 研究了目前可用的最受欢迎的开源基础模型（即已进行预训练但尚未微调或对齐的语言模型）。



