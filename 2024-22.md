# 云计算技术动态 2024 年第二十二期

## 分布式系统

**1.** **Megatron-LM：万亿模型并行训练，经典必读论文**

https://mp.weixin.qq.com/s/F2RP3ygOKrSA-veZIgQ6yA

**摘要:** 本文主要探讨了大型语言模型训练中的并行技术及相关性能分析。介绍了训练大型语言模型面临的内存和计算资源挑战，提出了张量并行、管道并行等模型并行策略，并对其进行了深入研究和创新。

**2.** **揭秘大型语言模型训练：突破AI极限的最新技术与未来趋势**

https://mp.weixin.qq.com/s/aXtJ04wlfIZdtFnKy_LvBA

**摘要:** 本文全面探讨了大型语言模型（LLM）训练系统及基础设施的相关内容。包括LLM的架构特点、训练工作负载特性、面临的挑战，以及相关的调查研究和基础设施设计等方面。

## 云计算技术

**1.** **LLM推理优化之Mélange：不是H100租不起，而GPU混布更有性价比**

https://mp.weixin.qq.com/s/JBM1oKg78AaqJbzyaRe-NA

**摘要:** 本文主要探讨了大模型推理加速中利用 GPU 异构性降低成本的相关问题。指出单一类型 GPU 部署大型语言模型服务并非最优方案，介绍了利用 GPU 异构性的降本空间、影响 LLM 推理成本效益的三个因素以及将最佳成本效益的 GPU 配置视为装箱问题的求解方法。

**2.** **深入理解 RDMA 的软硬件交互机制**

https://mp.weixin.qq.com/s/LaMp5ux5TmwKNw0gx_e3QQ

**摘要:** 本文主要介绍了 RDMA 技术的工作原理和软硬件交互机制。随着数据中心的发展，高性能网络对带宽和时延提出更高要求，阿里云自研高性能用户态协议栈并大规模使用 RDMA 技术。文章以 NVIDIA（原 Mellanox）的 RDMA 网卡为例，详细阐述了其工作原理、软件架构、内存管理、软硬交互等方面。

## 大模型技术

**1.** **LLM推理需要什么样的硬件平台？**

https://mp.weixin.qq.com/s/Znkunf3d4Oz9nhtN0IqcLA

**摘要:** 这篇文章主要介绍了用于研究大型语言模型（LLM）推理性能与平台设计参数关系的分析工具GenZ。文章涵盖了工作负载优化分析、平台特性分析、估算平台需求、极端规模要求等方面，并对相关工作和结论进行了阐述。

**2.** **Llama 3.1论文精读：为什么模型参数是4050亿？**

https://mp.weixin.qq.com/s/7y7PnJelVIms25lTO-KrjQ

**摘要:** 文本主要围绕 Meta 对 Llama 3 405B 模型的训练和优化展开，涵盖了模型参数确定、训练基础设施、训练中断情况、训练数据调整、后训练、数据质量评分、提升多语言和数学推理能力、长文本训练、工具使用、解决幻觉、性能表现、FP8 量化、理解多模态数据以及视觉与声音理解表现等多个方面。

## 技术之外

**1.** **AI与下一代计算平台：Jensen Huang对话Mark Zuckerberg**

https://mp.weixin.qq.com/s/2eVk5PPlumx-dvZsZL0CAQ

**摘要:** 本次对话主要围绕AI技术在内容创作、推荐系统、社交平台、企业应用等方面的发展和愿景展开，涉及Mark Zuckerberg和Jensen Huang对于AI相关技术和理念的深入探讨。

**2.** **深度解析DPU：技术革新与市场展望**

https://mp.weixin.qq.com/s/pjVa1XQ-lzOacuw0pzIELw

**摘要:** 本次网络研讨会围绕 DPU（数据处理单元）展开了深入探讨，包括其发展历程、市场现状、应用场景、未来发展方向以及与其他技术的关系等多个方面。
