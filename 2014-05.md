# 云计算技术动态 2024 年第五期

## 分布式系统

**1.** **使用 RDMA 提升微软 Azure 云的存储性能**

https://mp.weixin.qq.com/s/HDIgZ3J4UNHHsIh0pHeB4w

**摘要:** 本文翻译自 NSDI’23 论文《Empowering Azure Storage with RDMA》，该文章阐述了微软在 Azure 云中通过部署 RDMA 来提升存储性能。截至 2023 年 2 月，Azure 云中大约 70% 的流量是 RDMA 流量，并且 Azure 公有云所有 region 都支持 region 内 RDMA。RDMA 帮助我们显着提高磁盘 I/O 性能并节省 CPU 资源。

**2.** **数据中心以太网和RDMA：超大规模环境下的问题**

https://mp.weixin.qq.com/s/cUWY0qmvZDfFJKfFGQjSKA

**摘要:** 这篇文章列举了当下 RDMA 网络面临的问题和挑战, 预测学术界和行业将重新审视数据中心以太网, 这些现代化将推动人工智能、高性能计算和存储系统的新一代高性能网络生态系统，这些系统是超大规模数据中心的核心。这种发展将结束HPC和数据中心网络的融合！

## 云计算技术

**1.** **AI 集群基础设施刨根问底**

https://mp.weixin.qq.com/s/RCkn6escglbrXBAj1Kznug

**摘要:** 这篇文章从计算, 通信和存储的角度详细解读了 AI 集群基础设施的关键技术, 可以相对系统性理解 AI 基础设施技术.

**2.** **RDMA RNIC虚拟化**

https://mp.weixin.qq.com/s/xZBRrMJL_mEun4pk1zLS2g

**摘要:** RNIC虚拟化方案既要维持RDMA的高性能优势，又要满足云环境的部署要求。本文针对虚拟机和容器两种实体的典型RDMA虚拟化技术进行了调研，并且对相关领域的研究内容进行了总结和展望。

## 大模型技术

**1.** **LangChain初学者指南**

https://mp.weixin.qq.com/s/A_NB9LITrEj7c_UarsLTGg

**摘要:** LLM可以帮助我们将AI能力接入应用，LangChain作为开源工具，提供了接入各种主流LLM的接口，从而让我们以非常低的成本构建基于LLM的AI应用

**2.** **AI Infra论文阅读之将流水线并行气泡几乎降到零**

https://mp.weixin.qq.com/s/PXjYm9dN8C9B8svMQ7nOvw

**摘要:** 这篇论文介绍了在流水线并行中降低气泡的方法, 并且不会损失精度, 对 AI infra 领域的工作有比较多启发, 大家可以仔细看看论文.

## 技术之外

**1.** **Amazon S3 Express One Zone：激发高性能对象存储革命**

https://mp.weixin.qq.com/s/NN9fYVMPzfeL4o9v8NEqtA

**摘要:** 对象存储作为主存储的崛起，主要是由性能驱动的。对于数据需求巨大的AI/ML应用来说，它们需要低延迟、高吞吐量和高并发的对象存储。Amazon S3 Express One Zone对于已经投资于AWS生态系统的用户来说，将是一个非常有价值的服务。

**2.** **软件架构一致性 —— 被忽视的研发成本**

https://mp.weixin.qq.com/s/dlf-SUmystsc5PZf6ayVdw

**摘要:** 架构一致性问题是一个典型的 Scalability 问题，我们期望的是随着代码量的增长，使用服务的增长，应用数的增长，需要为此投入的维护成本不要线性增长。

