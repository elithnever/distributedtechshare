# 云计算技术动态 2024 年第十八期

## 分布式系统

**1.** **Google Fellow解读：分布式计算的第五个时代**

https://mp.weixin.qq.com/s/iur1mcN1o0pKcUlxtw-0IA

**摘要:** 本文探讨了分布式计算五个时代的演变，并详细讨论了第五代分布式计算的现状和未来趋势。文章以两位业界巨头 Mark Papermaster 和 Amin Vahdat 的对话为主线，分别从个人电脑时代、互联网时代、集群时代、大规模云计算时代和第五代分布式计算时代这五个角度，阐述了分布式计算技术不断发展与演变的过程。文章重点强调了在第五代分布式计算时代，随着摩尔定律的放缓，专用加速器的兴起以及对算力的需求不断增长，行业需要更加注重性能与功耗的平衡，并采用开放合作的模式来促进技术创新和行业发展。

**2.** **AI存储之VAST Data分析 架构篇**

https://mp.weixin.qq.com/s/TXPtyjkfDrdY0r9YB1b-yg

**摘要:** 本文主要介绍了VAST Data存储系统的设计架构，包括硬件、软件和元数据管理等方面。VAST Data采用了一种分布式、无共享的存储架构，通过使用NVIDIA BlueField-3 DPU和NVMe-oF协议，实现了高效的数据读写和元数据管理，并通过独特的混合架构，确保了元数据的可靠性和高性能访问。

## 云计算技术

**1.** **I/O Passthru：Linux内核中全新的I/O路径！**

https://mp.weixin.qq.com/s/-oWaVFSgqOHXLT8ODOd2tw

**摘要:** 本文介绍了 Linux 内核中一种新的 I/O 路径：I/O Passthru，旨在解决传统块存储接口无法满足新型非传统块存储设备（如 NVMe SSD）发展需求的问题。该路径通过字符设备接口，直接访问 NVMe SSD 的所有指令集，并利用 io_uring 的优势，实现高效、灵活的 I/O 访问，同时绕过块设备层，减少开销，提高性能。

**2.** **深入理解 RDMA 的软硬件交互机制**

https://mp.weixin.qq.com/s/mppfRPxGALSOWdP9vXplUg

**摘要:** 本文深入分析了RDMA技术在数据中心高性能网络环境下的工作原理及软硬件交互机制，通过对比传统Kernel TCP，突出了RDMA在减少延迟、提高系统性能方面的优势，同时讨论了其在内存管理、软硬交互方面的关键技术和挑战，为读者提供了全面理解RDMA技术及其应用场景的视角。

## 大模型技术

**1.** **再来谈谈大模型的分离式推理架构**

https://mp.weixin.qq.com/s/oRQMEsAj3LoD8UbVtST3Lw

**摘要:** 本文探讨了大模型分离式推理架构的软硬件演进, 着重分析了推理系统和训练系统的区别, 以及分离式推理架构在软件和硬件上的设计和优化方向. 文章认为, 分离式推理架构需要考虑数据和控制平面的分离, 以及GPU和CPU之间的紧密耦合和高效连接, 同时要兼顾成本、弹性和业务场景等因素.

**2.** **AI/ML中使用的集体操作（collectives），以太网卸载以及硬件实现**

https://mp.weixin.qq.com/s/ukxv0jkL5uHtyqbqvu2K0A

**摘要:** 通过Juniper的Trio架构和Broadcom的Jericho3-AI芯片的例子，文章展示了在网计算的灵活性和高效性，以及它们如何支持复杂的集体操作。这些技术的发展预示着未来在网络设备中实现更智能、更高效的数据处理的可能性。

## 技术之外

**1.** **AI与内存墙**

https://mp.weixin.qq.com/s/qdEI_e141IV9biCeiyq2rA

**摘要:** 20年里，硬件的峰值FLOPS增长了6万倍，而DRAM和互连带宽的增长却分别仅为100倍和30倍。根据这些趋势，内存——特别是芯片内和芯片间的内存传输——将很快成为制约大型AI模型服务能力的主要因素。因此，我们需要重新审视AI模型的训练、部署和设计，以及AI硬件的设计策略，以应对这一日益严重的“内存墙”问题。

**2.** **大模型算力需求推演**

https://mp.weixin.qq.com/s/d8_C7d1n8dEgT6mUdsjDGg

**摘要:** 这篇文章《Transformer FLOPs》主要讨论了在Transformer模型中计算浮点运算次数（FLOPs）的重要性和方法。本文通过详细的分析和示例，为读者提供了深入理解Transformer模型计算成本的途径，并强调了在设计和训练大型模型时考虑效率的重要性。
