# 云计算技术动态 2024 年第四期

## 分布式系统

**1.** **蚂蚁集团去中心化的高性能存储服务 LiteIO 正式开源**

https://mp.weixin.qq.com/s/u1sN3VVoCFrUYqV_PhJohA

**摘要:** LiteIO 是一款高性能、易扩展的云原生块设备服务，专为超融合架构下的 Kubernetes 设计。LiteIO 是将本地磁盘/逻辑卷，通过网络的方式共享给远程其他服务器使用，结合云原生 Kubernetes 的调度，将一系列磁盘统一管理、池化的通用技术。

**2.** **重新审视 CXL 时代下的分布式内存**

https://mp.weixin.qq.com/s/UmUoxFZevfAmcZzyG1ZGLQ

**摘要:** 随着网络和互联技术的飞速发展，研究者在逐渐改变对于该领域的看法，特别是随着 CXL技术的推出，我们站在了一个重新思考传统分布式编程范式的新起点。这个技术突破促使我们必须重新评估分布式共享内存在现代分布式系统中的应用潜力。

## 云计算技术

**1.** **Orion/猎户座：谷歌软件定义的网络控制平面**

https://mp.weixin.qq.com/s/LKl9A_JHgRlLrW4kj0WC4A

**摘要:** 这篇文章介绍了谷歌的Orion系统，一个分布式软件定义的网络平台，部署在谷歌的数据中心（Jupiter）和广域（B4）网络中。Orion是围绕一个模块化的微服务体系结构设计的，该体系结构具有一个集中(central)发布-订阅数据库，以实现一个分布式的、紧耦合的、软件定义的网络控制系统。Orion支持基于意图的管理和控制，具有高度的可扩展性，并符合全局控制层次结构。

**2** **AI Infra论文阅读之通过打表得到训练大模型的最佳并行配置**

https://mp.weixin.qq.com/s/D-14J482SFQf-zh-EFa-1w

**摘要:** 这次阅读一篇mlsys的一篇新论文，《Efficient Parallelization Layouts for Large-Scale Distributed Model Training》，作者在 Megatron-LM 基础上通过对各种训练调优方法进行组合打表获得了一些比较有趣的结论和发现，

## 大模型技术

**1.** **Mistral AI：探索LLM推理的吞吐、时延及成本空间**

https://mp.weixin.qq.com/s/-Q11Uix-PpYszrJiYpUSMQ

**摘要:** 选择正确的LLM推理栈意味着选择适合你的任务的正确模型，并配以适当的推理代码在适当的硬件上运行。本文介绍了流行的LLM推理堆栈和设置，详细说明其推理的成本构成；并讨论当前的开源模型以及如何充分利用它们，同时还涉及当前开源服务栈中仍然缺失的功能，以及未来模型将解锁的新功能。

**2.** **图解大模型推理优化之 KV Cache**

https://mp.weixin.qq.com/s/6q2LmwoFG2LcN0iHoZjjqw

**摘要:** 这篇文章将详细介绍了 KV Cache，这是一种大模型推理加速的方法。正如其名称所示，该方法通过缓存Attention中的K和V来实现推理优化。

## 技术之外

**1.** **加州伯克利大学计算机系是如何培养计算机人才的？**

https://mp.weixin.qq.com/s/bGgpoiClCld84wxVKk5a2A

**摘要:** 这篇文章简单总结了 UCB 的计算机课程设置, UCB的EECS系是计算机科学和电气工程融合在一起的，很多课程都有交叉。UCB的EECS系培养学生的目的，是为了学生在能够适应和主动学习未来的世界，因此它处处都体现了让学生发挥自己的能动性的特点。它不仅设置了EECS和CS两个学位供学生挑选，还设置了大量的选修课，让学生根据自己的兴趣来选择，甚至还有让学生自己开课。

**2.** **做大模型AI应用一定要了解的成本计算公式**

https://mp.weixin.qq.com/s/MpM8A3O6hMibvC8zBTDZMA

**摘要:** 在这个都在囤卡的时代，有必要算一算生成式AI 大模型训练和推理的成本以及可以优化的方向，这篇文章做了一个有意思的假设和换算，产品思维果然不一般！
