# 云原生技术动态 2023 年第十七期

## 分布式系统

**1.** **以Transformer结构为基础的大模型参数量、计算量、中间激活以及KV cache剖析**

https://mp.weixin.qq.com/s/3JYz6yrLeBr5ujip3LZe6w

**摘要:** transfomer 是 LLM 的基础技术, 本文分析采用decoder-only框架transformer模型的模型参数量、计算量、中间激活值、KV cache, 帮助开发者估算不同规模的模型在训练和推理场景的计算量.

**2.** **RDMA中的无损网络PFC与ECN**

https://mp.weixin.qq.com/s/4Pcswt9WY_etRCmnqSTNig

**摘要:** RDMA网络正是通过在网络中部署PFC和ECN功能来实现无损保障。PFC技术让我们可以对链路上RDMA专属队列的流量进行控制，并在交换机入口(Ingress port)出现拥塞时对上游设备流量进行反压。利用ECN技术我们可以实现端到端的拥塞控制，在交换机出口(Egress port)拥塞时，对数据包做ECN标记，并让流量发送端降低发送速率。

## 云计算技术

**1.** **从源码出发深入理解SPDK核心技术**

https://mp.weixin.qq.com/s/-ncHFhcpFmX3dSwoa0_VHw

**摘要:** 随着越来越多公有云服务提供商采用SPDK技术作为其高性能云存储的核心技术之一，intel推出的SPDK技术备受业界关注。本篇博文就和大家一起探索SPDK。

**2.** **突破性能瓶颈，火山引擎自研vSwitch技术实践揭秘**

https://mp.weixin.qq.com/s/K8XaU2ieeJspMhJO3JP5GA

**摘要:** 这篇文章分享了火山自研的 OpenVSwitch (BVS)系统的技术优化思路, 包括基于 dpdk , 热升级, 热迁移, 硬件卸载等实践思路.

## 云开发技术

**1.** **大语言模型微调：定制自己的微调数据集**

https://mp.weixin.qq.com/s/UPsfwxHObhaVB6yrm3atYw

**摘要:** 随着大型语言模型的普及，微调语言模型已成为适应特定应用场景的必要手段。为了构建高质量的微调数据集，需要考虑数据来源、数据质量、数据规模和数据相似性等因素。本文将介绍目前常见的微调数据集格式和微调数据集的基本处理方案。通过介绍微调数据集相关领域的近期研究进展，本文旨在帮助读者更好地定制化自己的微调数据集，以提升微调模型的质量。

**2.** **给容器加 CPU 居然可以不重启，怎么做到的？**

https://mp.weixin.qq.com/s/JvhVN8hwLBL3RwdJV76aRw

**摘要:** 非常实用的功能, 可以在运行状态下修改 pod 的资源规格, 不过这个功能还处于 alpha 阶段, 期待稳定版本尽快发布.

## 技术之外

**1.** **OpenAI Shyamal 分享LLM 创业前沿方向，我们所处的历史阶段，AI-IMPACT框架！**

https://mp.weixin.qq.com/s/cvfgGXyo0bn2AsSRM2YFPA

**摘要:** 在OpenAI 做Applied AI和Go-To-Market的Shyamal，梳理了AI工具、应用等关键领域典型公司，从OpenAI平台视角看到的生态演进历史阶段，还为创业者提出了一个产品设计框架，很有启发！

**2.** **不要总想着自己训练大模型，你的业务可能并不需要**

https://mp.weixin.qq.com/s/QflKQGk5FnA94kQgwzh61A

**摘要:** 这篇文章不讨论预训练，作者回到业务本质，结合大模型当前的发展和企业知识库，分享了对当前技术和行业发展的一些看法。
