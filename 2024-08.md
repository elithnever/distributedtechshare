# 云计算技术动态 2024 年第八期

## 分布式系统

**1.** **RocksDB深度解析**

https://mp.weixin.qq.com/s/caYA3CDd0tTMI_pikBCgEg

**摘要:** RocksDB是被广泛采用的内存嵌入式键值存储引擎，本文介绍了RocksDB的架构、技术原理、性能优化，帮助读者深入了解RocksDB，从而更好的使用这项技术。

**2.** **谈谈AI分布式训练不用RDMA的Google**

https://mp.weixin.qq.com/s/tBZCelQzMtX56lHCS08JDw

**摘要:** Google在其H100实例A3上并没有使用RDMA，而是采用了GPUDirect-TCPX,并且实例规格选择了4x200G的Intel IPU连接8个H100,远低于工业界普遍的3.2T/1.6T部署方式, 整体方案比较取巧, 性能要看实测了.

## 云计算技术

**1.** **谷歌流量整形技术Carousel解读**

https://mp.weixin.qq.com/s/5Z1IFK6S0aSkDxvH0OH2Mw

**摘要:** 本文介绍了谷歌流量整形技术Carousel，并简要介绍了谷歌其他流量整形和拥塞控制的实践进展。文章解释了流量整形技术的需求和令牌桶队列流量整形器的原理。

**2.** **揭秘谷歌 Falcon 传输协议**

https://mp.weixin.qq.com/s/L7m7lU5LSzfLqa4sNp0rSA

**摘要:** 近日，谷歌正式向 OCP 提交了 Falcon 协议草案, 协议草案包括OCP Specification_ Falcon Transport Protocol_Rev0.9和OCP Specification_ RDMA over Falcon Transport_Rev0.9, 这篇文章对协议草案进行了基本的介绍, 详细信息可以下载 pdf 文档查看.

## 大模型技术

**1.** **Meta | Wukong: 大规模推荐系统中的Scaling Law探索**

https://mp.weixin.qq.com/s/6XzQ7mZVJbYgk5py5GXKAw

**摘要:** 本文介绍了Wukong模型，一种基于堆叠的因子分解机（FM）的网络架构，旨在在推荐领域建立一个缩放定律。该模型通过调整超参数来放大整个模型，并展示了在参数缩放过程中相对于其他模型的优势。

**2.** **字节跳动打造MegaScale：用于训练大模型LLM的“万卡集群”**

https://mp.weixin.qq.com/s/waeRs0PXzU7owKHcTkCfBQ

**摘要:** 字节跳动介绍了他们用于训练大语言模型的生产系统MegaScale。MegaScale搭建了超过10000块GPU的单一集群，在12288个GPU上训练175B LLM模型时，MegaScale实现了55.2%的模型FLOP利用率（MFU）。该系统还包含一套诊断工具用于监控系统组件和事件，找出根本原因，并实现容错功能。用这个系统，不论啥错误10分钟就可以找到，15分钟就可以实现上一个检查点重启。

## 技术之外

**1.** **打造OpenAI GPT超算：微软云上生成式AI创新**

https://mp.weixin.qq.com/s/Imt4Fl6Wbrik2F037WE8hQ

**摘要:** 这是微软Azure首席技术官Mark在斯坦福大学研讨会上的演讲内容，介绍了微软Azure在生成式AI模型训练推理方面的优化和创新，包括与OpenAI的合作、超级计算机、Project Forge等项目。他还探讨了人工智能研究趋势和机密人工智能的重要性。Mark强调微软不仅提供硬件和模型，还与人工智能公司合作为客户提供服务。他还分享了关于GitHub Copilot、人工智能遗忘项目等个人研究。讲座内容详尽，涵盖技术和创新方面。

**2.** **NVIDIA 最新 GPU 解读：GB200、NVL72、SuperPod-576GPU**

https://mp.weixin.qq.com/s/J5lSuGS2S-0JBTMy3N-vOQ

**摘要:** 本文介绍了NVIDIA最新GPU的参数、互联方式以及与之前型号的对比。重点介绍了H200、B100和B200的显存和算力，以及NVLink和NVSwitch的带宽和GPU数量支持。

