# 云计算技术追踪 2024 年第二十六期

## 分布式系统

**1.** **多DC联合训练：谷歌，微软和OpenAI的AI Infra之争**

https://mp.weixin.qq.com/s/xvPidXyHOUmVy6yQvZCAXQ

**摘要:** 多 DC 联合训练是当前国内智算行业热门话题，三大运营商已开启研究和试点。2024 光博会期间，该话题备受关注。多 DC 联合训练不仅国内重视，海外科技巨头也早有布局。国际分析机构 semianalysis 发布研究报告，对 Google、OpenAI 和微软在该场景的问题、技术路线和竞争策略做了分析。总结指出多 DC 联合训练是海内外在 AI Infra 领域投资和竞争焦点，海外系统性研究更靠前；训练容错是关键未解决问题，各厂商私有容错训练技术重要且封闭；谷歌 CPU 时代分布式系统经验是 GPU 时代竞争力；多 DC 联合训练需创新训练策略，异步训练策略将受更多研究，OpenAI 和 Google 各有优势；该训练典型受益行业是电信网络，相关产品增长空间大；AI Infra 领域软件技术栈也很重要。

**2.** **Singularity：面向全球规模、抢占式和弹性调度的AI**

https://mp.weixin.qq.com/s/uN4fl9l8j4ync1pcZBhrDA

**摘要:** Singularity 是微软的全球分布式调度服务，用于高效且可靠地执行深度学习训练和推理工作负载。它通过一个新颖的工作负载感知调度器，透明地抢占和弹性扩展深度学习工作负载，以实现高利用率，同时不影响它们在全球 AI 加速器（例如 GPU、FPGA）集群上的正确性或性能。Singularity 中的所有作业默认都是可抢占的、可迁移的，并且具有动态可调整弹性特性。

## 云计算技术

**1.** **一文讲清 NCCL 集合通信原理与优化**

https://mp.weixin.qq.com/s/VtUFQ17G4ZICkjyWLhVGCg

**摘要:** 本文主要介绍了大模型训练中的集合通信技术，包括不同的并行模式以及集合通信库 MPI 和 NCCL 的特点、原理等内容。大模型分布式训练需要大规模 GPU 卡并行，常见并行策略有数据并行、模型并行（流水并行、张量并行）、序列并行、专家并行等，这些并行模式都离不开集合通信。接着介绍了 MPI 的概念、常见集合通信算子及与 NCCL 的区别，NCCL 专为 NVIDIA GPU 设计，具有低延迟、高吞吐量等特点，其通信方式有 GPU Shared Memory、GPU Direct P2P、NVLink 等，架构与 MPI 类似，还介绍了 GPU 拓扑结构和通信算法，最后对网络互联技术的发展进行了总结。

**2.** **AI基础设施的未来：谷歌与微软在多数据中心训练中的竞争态势**

https://mp.weixin.qq.com/s/3WgUaNv5ZzVn1Lp8wVBD-Q

**摘要:** 本文对比了谷歌与微软在 AI 基础设施方面的能力，包括基础设施与扩展能力、冷却技术、能源效率、AI 技术与产品、通信网络等方面。同时还介绍了多数据中心分布式训练、容错训练、训练策略、调制与复用技术、电信网络部署以及 AI 基础设施的未来发展趋势等内容。

## 大模型技术

**1.** **如何理解OpenAI o1**

https://mp.weixin.qq.com/s/QdVSq8q7wLWtPakdZdqidA

**摘要:** 本文主要探讨了 OpenAI 的 o1 模型及其相关问题，包括 o1 的意义、与 GPT--4o 的比较、对 Prompt 工程的影响、对 Agent 的作用、预训练 Scaling Law 的来源以及 o1 提到的 RL Scaling law 等方面。

**2.** **关于 OpenAI 发布 o1 系列模型的分析及其展望**

https://mp.weixin.qq.com/s/soIBTadKxLwxDsq6YR1C6g

**摘要:** 本文主要介绍了 OpenAI 的 o1 模型及其影响。从去年的 Q * 传言到今年的 Strawberry，o1 模型用强化学习方法提升了大模型的推理能力。它有两个版本，o1 preview 和 o1 mini，后者在成本和速度上更适合大多数任务。o1 的基本原理是用推理时间换训练时间，其定价较高，但购买的是推理能力的溢价。强化学习在提升模型推理能力方面价值重大，同时模型对齐也很关键，很多人对其价值认识不足。作者预测接下来几个月，基于慢思考能力的 AI Agent 即将到来，有望解决 AI Agent 缺少 PMF 的问题，实现 AI 在各行各业的真正落地。

## 技术之外

**1.** **大模型多数据中心训练：OpenAI 雄心计划，力压Google基础设施**

https://mp.weixin.qq.com/s/fQyA0v6Hmb8gxZoNzW5aXw

**摘要:** 本文主要讨论了 AI 基础设施建设中多数据中心训练的现状、挑战及未来发展趋势。由于物理因素限制，传统单数据中心训练大型模型已达极限，各大公司纷纷布局多数据中心训练。Google 在计算系统和基础设施方面具有领先优势，但长期计划不如 OpenAI 和 Microsoft 激进。微软和 OpenAI 正大力建设超密集液冷数据中心园区，并计划互联超大型园区构建分布式训练系统。文章还深入探讨了分布式训练的基础知识、容错训练、训练策略以及多数据中心训练面临的带宽和延迟问题。

**2.** **强化学习之父Rich Sutton ： 痛苦的教训**

https://mp.weixin.qq.com/s/-R5eT6D-BzGAnJueXMgPBw

**摘要:** Richard Sutton 是加拿大计算机科学家，DeepMind 杰出研究科学家及阿尔伯塔大学教授，被认为是现代计算强化学习奠基人之一。他指出从人工智能研究中可汲取的教训是利用计算能力的通用方法最终最有效，以计算机象棋、围棋、语音识别、计算机视觉等领域为例，阐述了最初人们试图利用人类知识，后来才通过拥抱搜索和学习取得更大成功，强调构建人类思考方式的方法长期行不通，应吸取教训，认识到通用方法的力量及鼓励人工智能系统自主发展新方法。
