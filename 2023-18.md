# 云原生技术动态 2023 年第十八期

## 分布式系统

**1.** **LangChain: 大语言模型的新篇章**

https://mp.weixin.qq.com/s/gPfYTxwiCkFa4fck0weBRA

**摘要:** 本文介绍了LangChain框架，它能够将大型语言模型与其他计算或知识来源相结合，从而实现功能更加强大的应用。接着，对LangChain的关键概念进行了详细说明，并基于该框架进行了一些案例尝试，旨在帮助读者更轻松地理解LangChain的工作原理。

**2.** **一文搞懂LangChain**

https://mp.weixin.qq.com/s/TfrxNJyICNntm_U7xOSuvw

**摘要:** 想要借助 OpenAI 或 Hugging Face 创建基于大语言模型的应用程序，有两个最著名的库，即 Haystack 和 LangChain，它们可以帮助我们创建基于大语言模型的端到端应用程序或流程。

## 云计算技术

**1.** **黄东旭：我对数据库如何Serverless 化的一些思考**

https://mp.weixin.qq.com/s/7YXSO3n7Y-SgZxgcpbQtoQ

**摘要:** serverless 不仅仅是简单的让用户看不到服务器, 而是需要在计费单元, 隔离, 弹性, 可靠等多租户能力, 和托管型相比是一个更为复杂的设计架构.

**2.** **面向大模型的存储加速方案设计和实践**

https://mp.weixin.qq.com/s/c4MWpBuYK0b1DDufeDV1vg

**摘要:** 这篇文章分享了百度沧海·存储在大模型场景下的加速方案及实践经验, 核心包括样本读取, checkpoint 存储, 模型分发三大主要流程的优化, 「加速」从来不止于单纯的性能提速，流程的高效和环节的顺畅也同样重要.

## 云开发技术

**1.** **AIGC 利器 Ray 云原生探索之路--分布式构建本地知识库**

https://mp.weixin.qq.com/s/K96d-UUnIX0tyWpL6Z7cQA

**摘要:** 本文结合 Ray Core、Ray Serve、KubeRay、LangChain、Embeddings、向量数据库、LLM、Kubernetes 和 GPU 方案来构建知识库可以更大程度的充分利用资源，也可以更大程度的提升整体的灵活性和效率。

**2.** **Hugging Face Transformer：从原理到实战的全面指南**

https://mp.weixin.qq.com/s/9HOWejCRsYoXWs5o81B3kw

**摘要:** Hugging Face 的火爆离不开他们开源的这个 Transformers 库。这个开源库里有数万个我们可以直接调用的模型。这篇文章从Transformer的架构和具体的案例来介绍Hugging Face Transformer。

## 技术之外

**1.** **开源不等于免费：Red Hat 调整 CentOS 项目带来的思考**

https://mp.weixin.qq.com/s/dq5hGh6xi9AnQ-QpipvSwA

**摘要:** 开源不等于免费，也不等于无限制。开源软件是一种基于协作和共享的软件开发模式，它既有利于软件的质量和创新，也有利于软件的普及和推广。但是，开源软件也需要遵循一定的规则和协议，它们既保护了软件作者的权利和利益，也保护了软件用户的自由和权利。

**2.** **LLM对程序员的冲击和影响**

https://mp.weixin.qq.com/s/_Kh8IzsfghT4fPWknesnzA

**摘要:** 彼得德鲁克说过“动荡时代的最大风险不是动荡本身，而是企图以昨天的逻辑来应对动荡”，全新的时代需要全新的思维模式，然后我们拭目以待。


