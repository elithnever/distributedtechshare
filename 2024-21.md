# 云计算技术动态 2024 年第二十一期

## 分布式系统

**1.** **从零开始深入理解存储引擎**

https://mp.weixin.qq.com/s/sEml0lH2Zj-b_sIFRn2wzQ

**摘要:** 本文主要围绕数据库相关的技术和概念进行了深入探讨，包括数据密集型应用中数据库的选型、单机存储引擎的构建与优化、不同存储引擎的对比、数据库的类型与应用场景，以及数据库的可靠性、可扩展性和可维护性等方面。

**2.** **LLama 405B 技术报告解读**

https://mp.weixin.qq.com/s/8RYqgfuYga0YU8H8XqNNOA

**摘要:** 这篇文章主要介绍了 Meta 发布的 Llama 3 的技术报告，包括预训练数据、模型结构、scaling law、infrastructure/硬件/网络、预训练方法、后训练（对齐）等方面的内容，还提及了将图像、视频和语音能力集成到 Llama 3 中的实验结果。

## 云计算技术

**1.** **一文搞懂iWARP RDMA**

https://mp.weixin.qq.com/s/N1p0gvu-kp7uihRYFNdicQ

**摘要:** 本文主要介绍了 RDMA 协议中的 iWARP，包括其概念、历史、工作原理、特点、与其他协议的对比等方面。

**2.** **Meta AI网络演化**

https://mp.weixin.qq.com/s/CoFtpdfI2-B6TqIgYTG2eQ

**摘要:** 本文主要介绍了 Meta 在 AI 网络架构演化方面的工作。包括构建 AI 应用网络时面临的挑战，如 AI 应用的多样性及对基础设施需求的变化等，并分享了从灵活基础设施、大型 GPU 集群及前后端网络联合优化等方面解决问题的措施，还强调了测试和基准的重要性。

## 大模型技术

**1.** **NSDI 2024 大型语言模型负载特征分析**

https://mp.weixin.qq.com/s/hAMzT5LXjpYR8H6JuMPRiQ

**摘要:** 本文深入研究了大语言模型（LLMs）在开发过程中面临的挑战与应对策略，基于对Acme GPU数据中心为期六个月的LLM开发工作负载跟踪数据的分析。涵盖了LLM开发的流程、背景、工作负载特征、基础设施利用以及环境影响等方面。

**2.** **掌握大语言模型技术：推理优化**

https://mp.weixin.qq.com/s/zvxSTNiqqbtA8u5iXOUmNw

**摘要:** 本文主要探讨了大型语言模型（LLM）在推理过程中面临的挑战及相应的解决方案，涵盖了模型结构、内存需求、并行化方法、注意力机制优化、缓存管理、模型优化技术以及模型服务技术等多个方面。

## 技术之外

**1.** **谈谈AISys架构师的基本素养**

https://mp.weixin.qq.com/s/yz8axx6PcOICIUWH-H57yA

**摘要:** 本文围绕量化交易、AISys 架构师的素养等内容进行了深入探讨。涵盖了量化交易的流程与技术、算法的演进趋势及考量、算力相关的 GPU 架构与并行策略、系统层面的资源池化与互联问题等，并在文末借梁总的话强调了在技术变革中应持有的态度。

**2.** **Jeff Dean，ML发展趋势**

https://mp.weixin.qq.com/s/i899hcidaGC5GAuoMceWtQ

**摘要:** 本次演讲概述了机器学习领域的一些关键趋势和进步，其中强调了数据规模、模型复杂性和专用硬件在推动机器学习发展中的作用，介绍Gemini多模态学模型及功。同时重点探讨其在科学、工程和医疗健康领域的应用前景，涵盖谷歌众多团队的最新研究成果。
