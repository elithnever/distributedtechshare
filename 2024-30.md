# 云计算技术动态 2024 年第三十期

## 分布式系统

**1.** **Ray在微信AI计算中的大规模实践**

https://mp.weixin.qq.com/s/1CH7Yki4AB08tJ1eDVVkhQ

**摘要:** 微信在 AI 计算中有大量应用场景，包括流量分发、产品运营和内容创作，但使用现有后台基础设施实现 AI 应用时遇到诸多问题，如资源成本高、部署复杂、应用编排效率低、平台缺乏等。为解决这些问题，微信引入 Ray 作为分布式底座构建 AI 计算平台 AstraRay，进行了大规模实践。

**2.** **从PB到EB：MinIO对象存储引领AI数据基础设施的未来**

https://mp.weixin.qq.com/s/vhyQqGgx90IlLGYyRUY6bw

**摘要:** 本文主要介绍了 MinIO 对象存储在 AI 数据基础设施中的应用，包括面临的挑战、核心技术、部署与管理、应用场景等方面。具体内容涵盖了数据规模增长带来的挑战，如传统存储难以满足性能需求和管理需求；MinIO 的架构设计、性能优化、数据保护与安全、可观察性和可管理性等核心技术；MinIO 的部署方式和广泛的应用场景；以及对象存储与 AI 密不可分的原因和在大规模数据处理中的优势。

## 云计算技术

**1.** **Meta揭秘：大规模AI集群可靠性的突破性研究**

https://mp.weixin.qq.com/s/ZGNHaqqXoWUSu1OIHj5TvQ

**摘要:** 本文分享了管理两个大型多租户ML集群的经验，提供了量化分析、运营经验以及我们在理解和解决大规模可靠性问题方面的视角。

**2.** **面向AI/ML集群的高性能网络传输协议优化研究**

https://mp.weixin.qq.com/s/vuNVJXQSXwyLt0p183V_Mg

**摘要:** 本文主要介绍了两种针对高性能数据中心的网络传输技术 ——FASTFLOW 和 STrack。FASTFLOW 是一种基于发送端的拥塞控制算法，旨在解决现代数据中心中大规模 AI 训练和 HPC 应用产生的突发性流量带来的网络拥塞问题。STrack 是一种适用于 AI/ML 集群的可靠多路径传输协议，旨在提高 AI/ML 工作负载的性能。

## 大模型技术

**1.** **推算LLM训练的GPU内存需求**

https://mp.weixin.qq.com/s/g3URctaJWa9ddhr9BoMxVw

**摘要:** 本文将分析大语言模型训练的GPU内存需求，主要包括三个方面：训练数十亿参数基于Transformer的LLM时，每个GPU设备需要多少GPU内存；估算内存需求的公式是什么；如果模型无法匹配内存，在实践中应采取哪些措施来减少内存需求。

**2.** **vLLM这一年的新特性以及后续规划**

https://mp.weixin.qq.com/s/ISltFRwFSNlgsnrzUnBTiw

**摘要:** 本文主要介绍了 vLLM 的发展历史、过去一年的发展及接下来 Q4 规划。包括过去一年的工作内容、性能优化方法、多种特色功能支持以及未来的发展计划。

## 技术之外

**1.** **AI与深度学习简史**

https://mp.weixin.qq.com/s/wQhTXHqDYCLMmS1NJ_aodQ

**摘要:** 本文概述了人工智能和深度学习的历史，从 1956 年达特茅斯会议人工智能概念的诞生，到现代的大型语言模型和多模态 AI 系统。涵盖了早期人工神经网络、多层感知器、反向传播、卷积神经网络、递归神经网络和 Transformer 等关键里程碑，展示了深度学习在不同领域的应用和发展。

**2.** **微软 AI CEO 苏莱曼：AI 发展应首要立足人类需求与感受**

https://mp.weixin.qq.com/s/lxhkyAHfgmLvIeHh3yFlNQ

**摘要:** 微软 AI CEO 穆斯塔法・苏莱曼在清华大学发表主旨演讲，分享了对人工智能未来发展的深刻洞见。他指出人工智能发展应服务人类、解决社会挑战并负责任地进行。回顾自己在人工智能领域的经历，强调技术真正价值在于提升生活品质，如微软的 Copilot 将为用户打造动态互动体验。同时，人工智能应致力于解决重大社会挑战，如气候变化等问题，并在全球范围内积极推进相关项目。此外，强调在发展人工智能过程中不能忽视责任，要确保其透明、可解释、公平、安全，并建立有效治理框架，持续关注信任问题。

