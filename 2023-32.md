# 云原生技术动态 2023 年第三十二期

## 分布式系统

**1.** **机器学习硬件十年：性能变迁与趋势**

https://mp.weixin.qq.com/s/fjYRXcCabVFNaolzk4cpAQ

**摘要:** 本文分析了机器学习硬件性能的最新趋势，重点关注不同GPU和加速器的计算性能、内存、互连带宽、性价比和能效等指标。这篇分析旨在提供关于ML硬件能力及其瓶颈的全面视图。

**2.** **云原生机器学习平台技术综述**

https://mp.weixin.qq.com/s/C8Q8uHTN4FqP2iFJCMf-gw

**摘要:** 本文重点关注机器学习平台的技术难点及其在Kubernetes云原生底座之上的解决方案。覆盖编排、调度、存储、通信、推理等方方面面。

## 云计算技术

**1.** **谷歌Falcon传输层协议解读系列-Carousel流量整形**

https://mp.weixin.qq.com/s/bdjEfw317uQzzlD6q14efw

**摘要:** Carousel是一种可实现规模扩展的主机侧流级整形技术, Carousel是谷歌发表在2017年Sigcomm会议上的成果，主要专注于如何在主机侧实现大规模可扩展的流级整形技术.

**2.** **盘点GPU Fabric典型拓扑结构及拥塞控制技术**

https://mp.weixin.qq.com/s/wBWnXemGMGzjkDbifFthXQ

**摘要:** 本文探讨了针对GenAI训练工作负载进行优化的各种网络拓扑结构，如Meta的Rail-Only 拓扑和Dragonfly拓扑，以及网络中可能存在的一些拥塞点和各种拥塞控制解决方案。

## 大模型技术

**1.** **语言大模型的分布式训练与高效微调指南**

https://mp.weixin.qq.com/s/m_zMNx7xR58YwMyBgrO-CA

**摘要:** 本文专注于分布式训练策略的具体细节，特别是DeepSpeed和FSDP，并总结了以多GPU和多节点训练为主的不同高效微调方法。

**2.** **大模型时代的数学基础**

https://mp.weixin.qq.com/s/kDj4ii7fs9MnbFpgZ17IYw

**摘要:** 本文从Seq2Seq/RNN开始，然后介绍了Attention机制的产生和Transformer的各个组件，然后分析了Transformer带来的算力和内存约束，以及常见的在训练和推理的解决办法。

## 技术之外

**1.** **从reInvent 2023看亚马逊云如何打造IaaS竞争力**

https://mp.weixin.qq.com/s/kDj4ii7fs9MnbFpgZ17IYw

**摘要:** 亚马逊云科技的产品设计之道，“客户第一”理念深入产品骨髓。在性能、成本、安全方面一次次迭代进步，为用户带来真切的应用收益。这篇文章从计算、存储、网络和安全几个IaaS重点技术方面深入解读。

**2.** **OpenAI科学家Andrej Karpathy力荐，23年必读的大语言模型论文清单**

https://mp.weixin.qq.com/s/mt9W8Mf0LbZjbuRObyeWeQ

**摘要:** 特斯拉前AI总监、OpenAI现任知名科学家Andrej Karpathy 最近一个长达一小时的视频火了——**《给忙碌人的大语言模型介绍》**，无论你是机器学习专家还是刚刚开始学习人工智能的新手，看完这条视频都会有一些很棒的收获。

